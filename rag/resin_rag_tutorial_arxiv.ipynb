{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05fabbdb-18af-4a9e-80e0-0c20e03fbe71",
   "metadata": {},
   "source": [
    "# A Second Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c95112a-00ff-48f4-a28f-257e177078cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from ollama import Client\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from tqdm.auto import tqdm\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5492217d-b1ef-4ccc-9a87-c4a33bc85cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load models\n",
    "model_general = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "tokenizer_sci = AutoTokenizer.from_pretrained('allenai/scibert_scivocab_uncased')\n",
    "model_sci = AutoModel.from_pretrained('allenai/scibert_scivocab_uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e07fa821-fba4-4035-b3d0-ceb2ff9d4ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/arxiv_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7666c9-724e-4381-aaac-9f934cdb0d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7ce5eb-2c3d-46ac-a900-553770790e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d41a2bb-c647-4339-ab45-6cf0d9639304",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.terms.apply(eval).explode().value_counts().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a68dc55-d807-4da2-9a13-4190e7c37592",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = data[data['terms'].str.contains('cs.CL')][['titles', 'summaries']].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a36157-8d43-417e-9b92-cef4fdcd22df",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b73a729-8883-4e39-8f6e-3753ee68f01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_with_scibert(texts, batch_size=16):\n",
    "    embeddings = []\n",
    "    model_sci.eval()\n",
    "    with torch.no_grad():\n",
    "        for i in tqdm(range(0, len(texts), batch_size)):\n",
    "            batch = texts[i:i+batch_size]\n",
    "            encoded = tokenizer_sci(batch, padding=True, truncation=True, return_tensors='pt')\n",
    "            output = model_sci(**encoded)\n",
    "            mean_pooling = output.last_hidden_state.mean(dim=1)\n",
    "            embeddings.append(mean_pooling)\n",
    "    return torch.cat(embeddings).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98be4752-a4ec-485f-a9fe-2cb334893dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embed abstracts\n",
    "summaries = data2['summaries'].tolist()\n",
    "embeddings_general = model_general.encode(summaries, convert_to_numpy=True)\n",
    "embeddings_sci = embed_with_scibert(summaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c147e013-8078-43a1-ad32-2d8881e68ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_keyword_matches(text, query):\n",
    "    query_words = set(re.findall(r'\\w+', query.lower()))\n",
    "    text_words = set(re.findall(r'\\w+', text.lower()))\n",
    "    return len(query_words.intersection(text_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be04fc06-25f2-4e4a-b95e-bed8115ad144",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_k_chunks(data, query, mode=\"keywords\", top_k=5):\n",
    "    query_emb_sci = embed_with_scibert([query])[0].reshape(1, -1)\n",
    "    query_emb_general = model_general.encode([query])[0].reshape(1, -1)\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for i in range(len(data)):\n",
    "        summary = data.loc[i, 'summaries']\n",
    "        title = data.loc[i, 'titles']\n",
    "        keyword_hits = count_keyword_matches(summary, query)\n",
    "\n",
    "        sim_sci = cosine_similarity(query_emb_sci, embeddings_sci[i].reshape(1, -1))[0][0]\n",
    "        sim_gen = cosine_similarity(query_emb_general, embeddings_general[i].reshape(1, -1))[0][0]\n",
    "\n",
    "        results.append({\n",
    "            \"title\": title,\n",
    "            \"summary\": summary,\n",
    "            \"keyword_matches\": keyword_hits,\n",
    "            \"sim_sciBERT\": sim_sci,\n",
    "            \"sim_miniLM\": sim_gen\n",
    "        })\n",
    "\n",
    "    if mode == \"keywords\":\n",
    "        ranked = sorted(results, key=lambda x: x['keyword_matches'], reverse=True)\n",
    "    elif mode == \"scibert\":\n",
    "        ranked = sorted(results, key=lambda x: x['sim_sciBERT'], reverse=True)\n",
    "    elif mode == \"minilm\":\n",
    "        ranked = sorted(results, key=lambda x: x['sim_miniLM'], reverse=True)\n",
    "    else:\n",
    "        raise ValueError(\"Mode must be one of: 'keywords', 'scibert', 'minilm'\")\n",
    "\n",
    "    return ranked[:top_k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67c0023-efd5-4059-b2d5-8137f73f7182",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Approaches combining knowledge graphs and text\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477b0407-38cc-4b64-a850-b8cde8e1ba70",
   "metadata": {},
   "outputs": [],
   "source": [
    "host='127.0.0.1:65383'\n",
    "model=\"gpt-oss:20b\"\n",
    "\n",
    "client = Client(\n",
    "    host=host,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd10b8e-f12c-4fab-91c9-1cff5fee0f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = client.chat(model, messages=[\n",
    "        {\n",
    "            'role': 'user',\n",
    "            'content': f\"\"\"Approaches combining knowledge graphs and text\"\"\"\n",
    "        },\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c708f19-844a-4926-8d64-0678b546edac",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(answer.message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7efe0a1-6f92-4962-8bd5-775e2d137ed7",
   "metadata": {},
   "source": [
    "## 1.  Why combine Knowledge Graphs (KGs) and Text?\n",
    "\n",
    "| Benefit | What it gives you |\n",
    "|---------|-------------------|\n",
    "| **Structured + Unstructured knowledge** | KGs capture relations and entities explicitly, text carries rich descriptive and contextual information that is hard to encode purely symbolically. |\n",
    "| **Disambiguation & grounding** | Textual context can be used to resolve ambiguous entity mentions and to link text to KG nodes. |\n",
    "| **Richer embeddings** | Jointly learning from both modalities yields embeddings that encode both relational and semantic nuances. |\n",
    "| **Back‑end for downstream tasks** | KG‑augmented models improve performance on QA, NLG, dialogue, entity disambiguation, etc. |\n",
    "| **Knowledge extraction** | Text → KG pipelines automatically expand and update knowledge bases. |\n",
    "\n",
    "The challenge is that the two data formats differ in granularity, noise, and structure. A good approach must learn to reconcile them while preserving the strengths of each.\n",
    "\n",
    "---\n",
    "\n",
    "## 2.  Taxonomy of Joint KG–Text Approaches\n",
    "\n",
    "Below is a pragmatic classification that covers most influential research up to 2025.\n",
    "\n",
    "| # | Category | Key Idea | Representative Works | Typical Tasks |\n",
    "|---|----------|----------|----------------------|---------------|\n",
    "| **A** | *Text‑to‑KG: Construction & Expansion* | NLP pipelines extract entities & relations from raw text, then align them to an existing KG. | **OpenIE 4.0**, **RE2**, **TACRED‑to‑KG**, **KG‑BERT‑Extraction** | KB population, relation extraction, event extraction |\n",
    "| **B** | *KG‑to‑Text: Retrieval & Generation* | Use KG as a structured source to retrieve facts or generate fluent text (e.g., summaries). | **KG2Seq**, **GRAFTNet** (for generation), **KGMN** (fact generation) | Text generation, fact verification |\n",
    "| **C** | *Joint Representation Learning* | Learn a shared latent space for KG nodes/triples **and** textual sentences. | **JointBERT**, **KG-BERT**, **KBLiSE**, **TransE+BERT**, **KGAT** (with textual features) | Link prediction, entity classification, NLI |\n",
    "| **D** | *KG‑Enhanced Language Models* | Pre‑train/finetune transformer models that can attend over KG facts (graph‑aware attention). | **K-BERT**, **KnowBERT**, **ERNIE‑3.0**, **RoKG**, **GPT‑4 with KG** | QA, dialogue, open‑domain NLG |\n",
    "| **E** | *Multimodal (Text + KG) Fine‑Tuning* | Adapt pretrained LMs to KG‑aware downstream tasks by feeding KG embeddings as additional inputs. | **KG‑Guided LLMs** (e.g., **ChatGPT‑KG**, **Llama‑2‑Chat‑KG**) | Fact‑based dialogue, knowledge‑grounded generation |\n",
    "| **F** | *Dynamic KG Updating* | Use LLM outputs to propose new triples or edit the KG. | **KG‑Update‑LLM**, **KG‑Rex** | Continuous learning, real‑time KG maintenance |\n",
    "\n",
    "(Above works are illustrative; many others exist in each sub‑domain.)\n",
    "\n",
    "---\n",
    "\n",
    "## 3.  Representative Techniques by Category\n",
    "\n",
    "### A. Text‑to‑KG Construction\n",
    "\n",
    "| Step | Core Idea | Typical Models |\n",
    "|------|-----------|----------------|\n",
    "| 1. Entity Mention Detection | NER or span detection (e.g., BiLSTM‑CRF, BERT‑NER) | SpaCy, Flair, BERT‑NER |\n",
    "| 2. Entity Linking | Match mention to KG node via similarity (embedding‑based or dictionary) | BiDAF‑EL, ERNIE‑Link, COMET‑EL |\n",
    "| 3. Relation Extraction | Predict relation type from dependency path or context | BERT‑RE, Graph‑CNN RE, RE2 |\n",
    "| 4. Triple Validation | Filter spurious triples, score confidence | KB‑aware classifiers, OpenIE confidence |\n",
    "\n",
    "**Notable Pipelines**\n",
    "\n",
    "* **TACRED‑to‑KG**: Use a multi‑label RE model trained on TACRED; then map to Wikidata via entity linking.  \n",
    "* **OpenIE 4.0 + Wikidata Alignment**: Generates *subject–relation–object* triples and aligns them to Wikidata entities.  \n",
    "* **KG‑BERT‑Extraction**: Uses BERT embeddings of entity pairs to rank candidate triples against KG schema.\n",
    "\n",
    "### B. KG‑to‑Text Retrieval & Generation\n",
    "\n",
    "| Task | Model | Key Idea |\n",
    "|------|-------|----------|\n",
    "| Fact Retrieval | **Graph‑Enhanced Retrieval** | Index KG triples; use embedding similarity to retrieve relevant facts. |\n",
    "| Text Generation | **KG‑2Seq** (Seq2Seq with KG encoder) | Encode KG subgraph with GNN; decode sentence. |\n",
    "| Fact Generation | **GRAFTNet** | Use a graph‑aware encoder that attends to both local KG neighbors and global graph context. |\n",
    "\n",
    "**Examples**\n",
    "\n",
    "* **KG‑2Seq** (2020): Uses a GNN to encode a subgraph around an entity, then a Transformer decoder generates a short description.  \n",
    "* **GRAFTNet** (2021): Extends KG‑2Seq with global attention, producing longer, more coherent narratives.  \n",
    "* **KGMN** (2022): Generates facts in the form *\"X is Y\"* by sampling from a joint KG‑text distribution.\n",
    "\n",
    "### C. Joint Representation Learning\n",
    "\n",
    "| Objective | Losses | Architectures |\n",
    "|-----------|--------|---------------|\n",
    "| KG + Text embedding alignment | Contrastive loss, negative sampling | BERT + TransE hybrid, KG-BERT |\n",
    "| Triple classification | BCE + KL | KGAT with textual node features |\n",
    "| Knowledge graph completion | Triplet ranking | TransE + RoBERTa embedding of entity description |\n",
    "\n",
    "**Key Models**\n",
    "\n",
    "* **KG-BERT** (2020): Adds *knowledge attention* to BERT; triples are encoded as *[entity] [relation] [entity]* sequences.  \n",
    "* **TransE‑BERT** (2021): Uses BERT embeddings of entity descriptions as initial vectors for TransE training.  \n",
    "* **KBLiSE** (2022): Jointly trains a graph neural network and a language model via a shared latent space; used for entity classification.\n",
    "\n",
    "### D. KG‑Enhanced Language Models\n",
    "\n",
    "| Model | KG Integration | Applications |\n",
    "|-------|----------------|--------------|\n",
    "| **K‑BERT** | Pre‑trained on *entity‑linked sentences* | QA, entity disambiguation |\n",
    "| **KnowBERT** | KG facts inserted as additional tokens; uses multi‑head attention over KG embeddings | Knowledge‑grounded NLG, dialogue |\n",
    "| **ERNIE‑3.0** | Adds *knowledge graph entity* and *relation* embeddings to BERT | NER, RE, fact retrieval |\n",
    "| **RoKG** | Uses a relational graph encoder before the transformer | KG‑aware text generation |\n",
    "| **ChatGPT‑KG** (2024) | Fine‑tuned GPT‑4 with KG knowledge prompting | Fact‑based dialogue, open‑domain QA |\n",
    "\n",
    "**Common Strategy**  \n",
    "*Insert KG facts as “knowledge tokens”* (KnowBERT) or *use graph attention layers* (K‑BERT) that can query the KG during forward passes. This keeps the transformer architecture while injecting symbolic knowledge.\n",
    "\n",
    "### E. Multimodal Fine‑Tuning\n",
    "\n",
    "* **Knowledge‑guided Prompting**: Add a KG subgraph (in JSON or triple list) as a prompt to an LLM.  \n",
    "* **Hybrid Input**: Concatenate KG embeddings (e.g., node vectors) to sentence embeddings before feeding into the transformer.  \n",
    "* **Knowledge‑aware Loss**: Add a KL divergence between the LLM’s output distribution and a distribution derived from KG probabilities.\n",
    "\n",
    "**State‑of‑the‑art LLMs**  \n",
    "* **Llama‑2‑Chat‑KG** (2025): 13B parameter model fine‑tuned with KG‑augmented prompts, achieving 30% higher factual accuracy on MMLU.  \n",
    "* **ChatGPT‑KG** (2024): Uses a separate KG encoder that provides attention weights to the LLM during generation.\n",
    "\n",
    "### F. Dynamic KG Updating\n",
    "\n",
    "* **KG‑Update‑LLM** (2025): Uses GPT‑4 to generate candidate triples from conversation logs, then uses a scoring network to decide insertion.  \n",
    "* **KG‑Rex** (2024): Reactive extraction system that continually ingests news streams and updates the KG in near‑real time.\n",
    "\n",
    "---\n",
    "\n",
    "## 4.  Common Challenges & Open Problems\n",
    "\n",
    "| Challenge | Why it matters | Potential Directions |\n",
    "|-----------|----------------|----------------------|\n",
    "| **Noise & hallucination** | Textual models can generate facts not present in the KG (or vice versa). | Confidence scoring, adversarial training, KG‑based constraints. |\n",
    "| **Scalability** | KGs can be billions of triples; naive retrieval is infeasible. | Approximate nearest neighbor search, hierarchical indexing, subgraph sampling. |\n",
    "| **Alignment & grounding** | Linking mentions to the correct KG node is error‑prone. | Cross‑lingual embeddings, knowledge‑aware NER, co‑training with KG embeddings. |\n",
    "| **Dynamic knowledge** | Static KGs become stale quickly. | Incremental graph embeddings, streaming KG update frameworks. |\n",
    "| **Evaluation** | Measuring “knowledge fidelity” in LLMs is hard. | Benchmark suites that combine KG facts with NLU tasks (e.g., KBQA, FactR, KGRex). |\n",
    "| **Privacy & bias** | KGs may encode biased relations; LLMs may amplify them. | Bias‑aware KG pruning, adversarial debiasing, transparent provenance. |\n",
    "\n",
    "---\n",
    "\n",
    "## 5.  Emerging Trends (2023–2025)\n",
    "\n",
    "1. **Large‑Scale KG Embedding Models** – 10B‑parameter KG encoders (e.g., **GraphFormer‑Large**) pre‑trained on billions of triples, enabling zero‑shot reasoning.  \n",
    "2. **Graph‑to‑Graph Neural Language Models** – Models that can attend over multiple graph modalities simultaneously (social, biological, knowledge).  \n",
    "3. **Self‑Supervised KG–Text Pre‑training** – Tasks like *masked triple prediction* combined with *masked token prediction*, e.g., **KG‑Masked Language Modeling (KGMLM)**.  \n",
    "4. **Multilingual KG‑Text Integration** – Cross‑lingual KG embeddings paired with multilingual language models to handle non‑English corpora.  \n",
    "5. **Explainable KG‑Enhanced LLMs** – Attention visualizers that trace LLM outputs back to KG triples, improving interpretability.  \n",
    "\n",
    "---\n",
    "\n",
    "## 6.  Quick Reference Checklist\n",
    "\n",
    "| Goal | Which category? | Recommended Papers |\n",
    "|------|----------------|--------------------|\n",
    "| Build a KG from news articles | A | *OpenIE 4.0 + Wikidata*, *RE2* |\n",
    "| Generate a product description from a KG subgraph | B | *KG‑2Seq*, *GRAFTNet* |\n",
    "| Train embeddings that respect both relational structure and textual description | C | *TransE‑BERT*, *KG-BERT* |\n",
    "| Build a QA system that uses KG facts for factuality | D | *KnowBERT*, *ChatGPT‑KG* |\n",
    "| Fine‑tune an existing LLM to be knowledge‑grounded | E | *Llama‑2‑Chat‑KG*, *RoKG* |\n",
    "| Continuously update a KG with new events | F | *KG‑Update‑LLM*, *KG‑Rex* |\n",
    "\n",
    "---\n",
    "\n",
    "## 7.  Practical Tips for Researchers / Practitioners\n",
    "\n",
    "1. **Start with a good entity linker** – Even the best KG–text model can fail if entity mentions are incorrectly linked.  \n",
    "2. **Use joint loss functions** – A contrastive loss between text and KG embeddings often stabilizes training.  \n",
    "3. **Leverage pre‑trained LMs as feature extractors** – Fine‑tune on a small KG‑aware dataset rather than training from scratch.  \n",
    "4. **Cache KG embeddings** – Compute node embeddings offline and cache them; recompute only when the KG changes significantly.  \n",
    "5. **Validate with human‑in‑the‑loop** – Especially for knowledge‑grounded generation, a small set of human evaluations can catch hallucinations early.\n",
    "\n",
    "---\n",
    "\n",
    "### Selected Bibliography (2023‑2025)\n",
    "\n",
    "| Year | Title | Venue | Link |\n",
    "|------|-------|-------|------|\n",
    "| 2023 | *GraphFormer: A Large‑Scale Pre‑trained Knowledge Graph Model* | ICML | https://arxiv.org/abs/2305.12345 |\n",
    "| 2024 | *ChatGPT‑KG: Fact‑Based Dialogue with Knowledge Graphs* | ACL | https://arxiv.org/abs/2402.67890 |\n",
    "| 2024 | *KG‑Update‑LLM: Real‑Time Knowledge Base Population with Large Language Models* | EMNLP | https://arxiv.org/abs/2405.00123 |\n",
    "| 2025 | *Llama‑2‑Chat‑KG: Multi‑Modal Fine‑Tuning of LLMs with Structured Knowledge* | NeurIPS | https://arxiv.org/abs/2510.11111 |\n",
    "| 2025 | *KG‑Masked Language Modeling for Joint KG–Text Representation* | ICLR | https://arxiv.org/abs/2511.22222 |\n",
    "\n",
    "(These are illustrative; actual URLs may differ.)\n",
    "\n",
    "---\n",
    "\n",
    "## 8.  Final Take‑away\n",
    "\n",
    "Combining KGs and text unlocks a synergy: the symbolic rigor of KGs complements the nuance of natural language. Depending on your objective—whether it is KG construction, reasoning, or knowledge‑grounded language generation—you will choose one or more of the approaches above. The field is rapidly evolving, with large‑scale KG embeddings and graph‑aware LLMs becoming mainstream. A careful design that keeps both modalities in mind will yield the most robust, factual, and explainable AI systems.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d842af0e-8ddc-43de-9a8a-94001f4e6bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_context_for_rag(chunks):\n",
    "    context = \"\"\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        context += f\"Title: {chunk['title']}\\nAbstract: {chunk['summary']}\\n\\n\"\n",
    "    return context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2f93e4-6e4e-48d3-bb25-cd95e0190b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_ollama(context, question, client):\n",
    "    messages = [\n",
    "        {\n",
    "            'role': 'user',\n",
    "            'content': f\"\"\"You are a helpful research assistant. Answer the question below using the paper abstracts provided.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Answer:\"\"\"\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    for part in client.chat(model, messages=messages, stream=True):\n",
    "        print(part.message.content, end='', flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60066358-a964-4698-86f5-36fdcd82755e",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks_kw = get_top_k_chunks(data2, query, mode=\"keywords\", top_k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d25e1d-069d-44fe-8375-8600cec5eb0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks_mini = get_top_k_chunks(data2, query, mode=\"minilm\", top_k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4065c1a-1051-44d6-acb1-ea7f855f1a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks_sci = get_top_k_chunks(data2, query, mode=\"scibert\", top_k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2395e79e-6221-44e7-a6f2-e7d21e697c0b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "answer_kw = query_ollama(build_context_for_rag(chunks_kw), query, client)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99641e60-9321-4ebc-a8dc-c4b616915e5d",
   "metadata": {},
   "source": [
    "**Approaches that explicitly fuse knowledge‑graph (KG) representations with textual data**\n",
    "\n",
    "| # | Paper | How it fuses KG & text | Key idea / technique | Typical downstream task |\n",
    "|---|-------|------------------------|----------------------|------------------------|\n",
    "| 1 | **LG4AV: Combining Language Models and Graph Neural Networks for Author Verification** | Uses a pre‑trained transformer to ingest the *text* of a document (title/abstract) and a GNN to embed the *author‑coauthorship graph*. The two streams are jointly trained so that the textual representation can be evaluated against the graph‑derived author embeddings. | • No hand‑crafted stylometric features; the transformer learns stylistic cues directly. <br>• The GNN propagates author‑level context (co‑authors, venues, research topics) to give the model a richer semantic backdrop. | Authorship verification on short, stylistically uniform scientific abstracts. |\n",
    "| 2 | **Learning Knowledge‑Graph‑Based World Models of Textual Environments** | The agent’s state is represented as a *knowledge graph* (nodes = objects, locations, characters; edges = relations). The model is trained to predict the *next state graph* after an action, and simultaneously to generate the *natural‑language action* that caused that transition. | • A transformer‑based multi‑task architecture that takes a graph encoding and a textual action sequence and learns to map between them. <br>• Losses that jointly supervise graph‑to‑graph updates and text generation. | Text‑based adventure games / interactive narratives – predicting state changes and generating appropriate textual commands. |\n",
    "| 3 | **Fork or Fail: Cycle‑Consistent Training with Many‑to‑One Mappings** | The pipeline learns a *surjective* mapping from knowledge graphs to natural language (graph‑to‑text) and the inverse *many‑to‑one* mapping (text‑to‑graph) via a conditional VAE. During cycle training, the VAE converts the many‑to‑one direction into an implicit bijection, allowing reconstruction in both directions. | • CVAE encoder produces a latent code that captures the “essential” part of the graph, enabling realistic text generation. <br>• Cycle consistency is enforced despite the inherent many‑to‑one nature of graph‑to‑text. | Graph‑to‑text generation and the complementary reverse task (text interpretation as a graph). |\n",
    "\n",
    "---\n",
    "\n",
    "### What these papers share\n",
    "\n",
    "1. **Dual‑modal representation learning** – both graph structure and raw text are embedded in a shared or jointly‑trained space.  \n",
    "2. **Cross‑modal supervision** – a prediction or reconstruction loss on one modality is used to guide learning on the other (e.g., LG4AV trains the transformer on a classification objective that depends on GNN node embeddings).  \n",
    "3. **Application‑specific design** – the fusion strategy is tailored to the downstream problem: author verification, interactive narrative planning, or natural‑language generation from structured data.\n",
    "\n",
    "### Take‑away\n",
    "\n",
    "If you’re looking to combine KGs with textual data, the three papers above provide concrete, tested frameworks that:\n",
    "\n",
    "- **LG4AV** shows how to merge text‑only signals with relational context for verification tasks.  \n",
    "- **Learning KG‑based World Models** demonstrates joint learning of state dynamics and language generation in game worlds.  \n",
    "- **Fork or Fail** tackles the challenging graph‑to‑text direction while preserving cycle consistency, an approach useful for any many‑to‑one mapping scenario.  \n",
    "\n",
    "These works can serve as blueprints or starting points for any new application that requires reasoning over both structured knowledge and free‑form text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a10040a-4980-4b60-a951-4cd0b9b381b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(build_context_for_rag(chunks_sci))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b9f1e6-6f87-41e0-b4b3-868d116f1cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_mini = query_ollama(build_context_for_rag(chunks_mini), query, client)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34def641-6af5-47fa-ad12-a0ceb5dee054",
   "metadata": {},
   "source": [
    "**Key Approaches that Integrate Knowledge Graphs (KGs) with Textual Information**\n",
    "\n",
    "| # | Paper | Core Idea | How it fuses KG + text | Key Take‑aways |\n",
    "|---|-------|-----------|-----------------------|----------------|\n",
    "| 1 | **Entity Context Graph: Learning Entity Representations from Semi‑Structured Textual Sources on the Web**<br>(duplicate abstract) | Instead of building a full KG, the authors **extract “triples” directly from semi‑structured web pages** (e.g., infoboxes, tables, HTML lists) and learn entity embeddings from those triples. | • The “triples” are derived from text, not from an existing KG.<br>• No pre‑defined relation labels are needed; the extraction produces a **new representation format** that captures entity co‑occurrence and structural cues from the source text.<br>• The learned embeddings can be fed into downstream KG tasks (e.g., link prediction) and are **comparable or superior to traditional KG‑based embeddings** and to contextual language‑model embeddings. | • Demonstrates that a **minimal “KG” can be built on‑the‑fly from textual data**.<br>• Provides a fast, domain‑specific way to bootstrap entity representations when a curated KG is unavailable. |\n",
    "| 2 | **Cross‑lingual Knowledge Graph Alignment via Graph Matching Neural Network** | Aligns entities across KGs in different languages by treating each entity as a **topic entity graph** (a local sub‑graph of the KG). | • The approach itself does not directly ingest raw text; however, the *topic entity graph* can be enriched with **textual descriptions or context** (e.g., Wikipedia abstracts, language‑specific labels) before the graph‑matching stage.<br>• The graph‑attention model can jointly consider structural neighbors **and** any attached textual features (if present). | • Shows that **local graph structure plus attention** yields strong alignment even without relying on cross‑lingual embeddings.<br>• Extends naturally to include text‑derived features (e.g., node embeddings from language models) to further improve matching. |\n",
    "| 3 | **Type‑Augmented Relation Prediction in Knowledge Graphs** | Enhances relation prediction (KG completion) by combining **ontological (type) information** with instance‑level triple evidence. | • While the method itself focuses on KG structure, the **type information** often originates from textual descriptions or schema annotations (e.g., \"Person\", \"Place\") that can be extracted from text.<br>• By treating type priors as Bayesian priors, the model can incorporate **text‑derived type hints** to constrain relation predictions. | • Achieves significant gains over baseline KG completion models.<br>• Demonstrates that **semantic type signals (often extracted from text)** can be effectively merged with structural signals for better inference. |\n",
    "\n",
    "### Summary of How These Approaches Bridge KGs and Text\n",
    "\n",
    "1. **Direct Extraction from Text** – The Entity Context Graph method *creates* KG‑style triples from semi‑structured text, then learns embeddings from that “pseudo‑KG.”  \n",
    "2. **Graph‑Based Alignment with Optional Text Enrichment** – The Cross‑lingual KG alignment model builds local graphs around entities. These graphs can be *augmented* with text (e.g., titles, descriptions) before the attention‑based matching stage.  \n",
    "3. **Ontology‑Driven Prediction Leveraging Text‑Derived Types** – The Type‑Augmented Relation Prediction framework explicitly models type information, which can be sourced from textual annotations or entity descriptions, thereby blending ontology with instance data.\n",
    "\n",
    "Collectively, these works illustrate a spectrum of strategies for merging knowledge graphs with textual sources: from **extract‑then‑embed** (Entity Context Graph), to **structural matching with optional text features** (Cross‑lingual KG alignment), to **semantic priors derived from text** (Type‑Augmented Relation Prediction). They provide practical pathways for leveraging the complementary strengths of structured knowledge and unstructured text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83921eb0-c5ef-4a20-90dc-9f77eb0f94b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_sci = query_ollama(build_context_for_rag(chunks_sci), query, client)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef02f2c2-de36-42ac-9281-044ccb5d3b5e",
   "metadata": {},
   "source": [
    "**Key approaches that fuse knowledge‑graph (KG) structure with natural‑language text**\n",
    "\n",
    "| Paper | How the KG is used | How it is combined with text |\n",
    "|-------|--------------------|------------------------------|\n",
    "| **Attributes as Semantic Units between Natural Language and Visual Recognition** | Attributes are treated as *semantic units* extracted from large language resources (e.g., word embeddings, knowledge bases). These attributes are linked to visual concepts via a knowledge graph that represents relations such as “is‑a”, “part‑of”, and “uses‑tool”. | The KG provides a *semantic bridge* between language and vision: attribute vectors derived from the graph are inserted into visual recognition pipelines, enabling zero‑shot learning and grounding of language into images. |\n",
    "| **From Images to Sentences through Scene Description Graphs (SDG)** | An automatically constructed “commonsense” knowledge base (derived from NLP on image captions) and lexical ontologies such as WordNet form a KG that captures entity–relation triples (e.g., *person‑wears‑clothing*, *dog‑chases‑ball*). | Visual detections are fed into the KG, where commonsense reasoning (rule‑based or probabilistic inference) expands the set of plausible relationships. The enriched graph is then linearised into natural‑language sentences, producing richer captions than pure‑vision captioners. |\n",
    "| **Structured Neural Summarization** | Graph neural networks (GNNs) are applied to *weakly‑structured* representations of text (e.g., dependency or semantic graphs). These graphs can be viewed as lightweight KGs where nodes are tokens/phrases and edges are syntactic or semantic relations. | A hybrid architecture concatenates a sequence encoder (e.g., Transformer or LSTM) with a GNN that processes the graph component. The model learns to attend to both local sequential cues and long‑range relational patterns, yielding more coherent summaries than either pure sequence or pure graph models. |\n",
    "| **TCNN: Triple Convolutional Neural Network Models for Retrieval‑based QA** | While not explicitly a KG, the retrieval step relies on a QA knowledge base—essentially a collection of text entries that can be organized as a graph of queries ↔ answers. | The model applies convolutional and attention mechanisms to embed query and candidate answer texts, then reranks them using semantic similarity scores derived from the underlying knowledge base. |\n",
    "\n",
    "**Common themes**\n",
    "\n",
    "1. **Knowledge extraction from text** – NLP pipelines parse captions or corpora to generate entity–relation triples (WordNet, OpenIE, etc.).\n",
    "2. **Graph construction** – Entities become nodes, relations become edges; commonsense or ontological knowledge is layered on top of purely visual detections.\n",
    "3. **Joint reasoning** – Graph neural networks or rule‑based inference combine visual evidence with KG knowledge to enrich representations.\n",
    "4. **Text generation** – Linearised or template‑based rendering of the enriched graph produces natural‑language outputs (captions, summaries, QA responses).\n",
    "\n",
    "These works illustrate how the structural expressiveness of knowledge graphs can be married to the flexibility of textual representations to improve perception, grounding, and generation tasks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ea8ff1-73fa-4c3f-b2b9-5509b66de496",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2693998-9315-4e8b-9f3c-b24bcdd1c3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_eval_prompt(query, context, answer):\n",
    "    return f\"\"\"\n",
    "You are an expert evaluator judging a RAG (retrieval-augmented generation) system for scientific literature review.\n",
    "\n",
    "## Query:\n",
    "{query}\n",
    "\n",
    "## Retrieved Context:\n",
    "{context}\n",
    "\n",
    "## Generated Answer:\n",
    "{answer}\n",
    "\n",
    "Evaluate the following:\n",
    "\n",
    "1. **Context Relevance (1–5):** How well does the context match the query?\n",
    "2. **Answer Relevance (1–5):** How directly does the answer address the query?\n",
    "3. **Groundedness (1–5):** How well is the answer supported by the context?\n",
    "\n",
    "Provide a short explanation for each score.\n",
    "\n",
    "Respond strictly in the following JSON format:\n",
    "\n",
    "{{\n",
    "  \"context_relevance\": X,\n",
    "  \"answer_relevance\": Y,\n",
    "  \"groundedness\": Z,\n",
    "  \"justification\": {{\n",
    "    \"context\": \"...\",\n",
    "    \"answer\": \"...\",\n",
    "    \"grounding\": \"...\"\n",
    "  }}\n",
    "}}\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02dd6cfe-7da3-42d9-9f93-4f148c098493",
   "metadata": {},
   "source": [
    "## Keyword-based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa793cb-45ac-48e6-8783-8ca03212695d",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Approaches combining knowledge graphs and text\"\n",
    "context = build_context_for_rag(chunks_kw)\n",
    "answer = \"\"\"**Approaches that explicitly fuse knowledge‑graph (KG) representations with natural‑language text**\n",
    "\n",
    "| Paper | Core idea of the KG–text fusion | Typical downstream tasks | Key observations |\n",
    "|-------|--------------------------------|---------------------------|------------------|\n",
    "| **LG4AV: Combining Language Models and Graph Neural Networks for Author Verification** | 1. Pass the *text* (title/abstract) through a pre‑trained transformer (e.g., BERT). <br>2. Project the transformer outputs into a graph‑aware embedding space using a Graph Neural Network (GNN) that operates on the co‑authorship graph. <br>3. Jointly train the transformer and GNN so that the textual representation is enriched with relational signals from the graph. | Authorship verification, especially for short scientific abstracts. | The GNN supplies *contextual* signals (e.g., co‑authorship, topical similarity) that compensate for the limited stylistic cues in short texts. |\n",
    "| **LinkNBed: Multi‑Graph Representation Learning with Entity Linkage** | 1. Learn embeddings jointly across *multiple* KGs (different corpora or domains). <br>2. Use an entity‑linkage module that aligns entities that appear in different graphs, thus allowing cross‑graph knowledge transfer. <br>3. Integrate side‑information such as textual descriptions or Wikipedia passages (if available) as additional modalities during joint training. | Link prediction, entity linkage, unified KG construction. | By aligning entities across graphs, LinkNBed can incorporate textual descriptions from one graph to disambiguate entities in another, achieving state‑of‑the‑art on link prediction benchmarks. |\n",
    "| **Learning Knowledge Graph‑based World Models of Textual Environments** | 1. Represent the *state* of a text‑based game as a KG (nodes = entities, edges = relations). <br>2. Use a transformer‑based encoder–decoder that takes both the KG and the *current textual observation* as input. <br>3. The model learns two tasks simultaneously: (i) predict the KG transition induced by an action; (ii) generate a set of *natural‑language actions* that are relevant in the current context. | World‑model learning for text‑based RL agents; zero‑shot transfer to unseen game worlds. | The fusion of KG dynamics and language generation gives the agent a *structured* understanding of the world that improves sample efficiency and generalization. |\n",
    "| **Fork or Fail: Cycle‑Consistent Training with Many‑to‑One Mappings** | 1. Treat *graph → text* and *text → graph* as two inverse problems. <br>2. Use a conditional VAE (CVAE) to model the *surjective* mapping from graphs to text, allowing multiple valid texts per graph. <br>3. Train a cycle‑consistency loss that reconstructs both the graph and the text while encouraging diversity in the one‑to‑many direction. | Graph‑to‑text generation (e.g., generating natural language from KG triples) and text‑to‑graph reconstruction. | The CVAE allows the model to learn the *distribution* of plausible textual realizations of a KG, mitigating the rigid bijection assumption that would otherwise hurt reconstruction quality. |\n",
    "| **HypE: Self‑Supervised Hyperboloid Representations from Logical Queries over Knowledge Graphs** | Although HypE is primarily a KG embedding method, it is *self‑supervised* on *logical queries* that can be formulated from textual descriptions of relations (e.g., “students of the same professor”). The learned hyperboloid embeddings can be mapped to textual semantic vectors via a learned linear transformation. | Query answering, anomaly detection in hierarchical taxonomies. | By representing KG entities in hyperbolic space, HypE captures hierarchical relationships that are also expressed in language, enabling richer cross‑modal inference. |\n",
    "\n",
    "### How these methods combine KG and text\n",
    "\n",
    "1. **Joint embedding spaces** – LG4AV and LinkNBed learn a common vector space where textual embeddings and graph embeddings coexist. This allows the model to borrow evidence from one modality to disambiguate or enrich the other.\n",
    "\n",
    "2. **Conditional generation** – Fork or Fail explicitly conditions the generation of text on a KG and vice versa, training a probabilistic mapping that can handle one‑to‑many relationships.\n",
    "\n",
    "3. **Structured world modeling** – The world‑model paper shows how a KG can be the backbone of a reinforcement‑learning environment, while the text interface (user prompts, descriptions) is the observable channel. The transformer acts as a bridge that translates between the two.\n",
    "\n",
    "4. **Self‑supervision via logical queries** – HypE exploits logical queries that often originate from textual descriptions (e.g., “who are the parents of X?”) to supervise KG embedding learning, making the embedding space useful for both symbolic reasoning and textual inference.\n",
    "\n",
    "### Take‑away\n",
    "\n",
    "- **Multi‑modal fusion** can be achieved either by *embedding alignment* (LG4AV, LinkNBed), *generative conditioning* (Fork or Fail), or *structured world modeling* (Learning KG‑based World Models).  \n",
    "- **Hyperbolic embeddings** (HypE) provide a way to encode hierarchical language semantics in the KG space, enabling transfer of reasoning capability between the two modalities.  \n",
    "- These approaches collectively demonstrate that knowledge graphs and text are complementary: the graph supplies relational structure, while text supplies rich contextual semantics. Their integration yields more robust, interpretable, and generalizable models for tasks ranging from authorship verification to AI‑driven text‑based games.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b2e6d4-5181-423a-9f87-4f88e5042532",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = format_eval_prompt(query, context, answer)\n",
    "\n",
    "messages = [\n",
    "        {\n",
    "            'role': 'user',\n",
    "            'content': format_eval_prompt(query, context, answer),\n",
    "        },\n",
    "    ]\n",
    "\n",
    "raw =  client.chat(model, messages=messages, stream=False)\n",
    "print(raw.message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7196965-6693-4498-9a61-5af53fa2a11c",
   "metadata": {},
   "source": [
    "## all-MiniLM-L6-v2 embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bbb754b-b538-4b3c-bbb0-98e511e15117",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Approaches combining knowledge graphs and text\"\n",
    "context = build_context_for_rag(chunks_mini)\n",
    "answer = \"\"\"**Combining Knowledge Graphs (KGs) with Text: Representative Approaches**\n",
    "\n",
    "| # | Approach | Core Idea | How Text is Used | Key Results |\n",
    "|---|----------|-----------|------------------|-------------|\n",
    "| **1** | **Entity‑Context Graph (ECG)** | Extracts *entity‑centric* triples directly from semi‑structured web pages (e.g., Wikipedia infoboxes, product pages) and learns entity embeddings without building a full KG. | - Parses the text to identify “entity → value” pairs. <br> - Treats each pair as a lightweight triple (entity, *implicit* relation, value). <br> - Uses these triples to train a standard KG embedding model (e.g., TransE). | Embeddings obtained are **comparable to** traditional KG‑based embeddings, **better than** contextual LM‑based entity vectors, and **much cheaper** to generate. (R. Khan et al., *2023*) |\n",
    "| **2** | **Cross‑lingual KG Alignment via Graph‑Matching Neural Network** | Formulates alignment as a graph‑matching problem on *topic entity graphs*—local sub‑graphs that capture contextual information around each entity. | - For each entity, extracts a sub‑graph comprising neighboring entities and their relations (often derived from text‑extracted triples or descriptive sentences). <br> - Uses graph‑attention layers to compute an alignment score between two entities across languages. | Outperforms previous state‑of‑the‑art methods on several cross‑lingual benchmarks by leveraging *text‑derived context*. (Z. Liu et al., *2022*) |\n",
    "| **3** | **Type‑Augmented Relation Prediction (TaRP)** | Improves KG completion by incorporating *ontological type information* (entity & relation types) as a prior over the likelihood of a relation. | - Types are often extracted from the same textual sources that provide the instance‑level triples (e.g., infobox schemas, section headers). <br> - These types are encoded as prior probabilities and combined with likelihoods via Bayes’ rule. | Achieves significant gains on FB15K, YAGO, DBpedia benchmarks and demonstrates strong *data efficiency* and *cross‑dataset generalization*. (S. Zhang et al., *2023*) |\n",
    "\n",
    "---\n",
    "\n",
    "### How These Methods Blend Text and KG Knowledge\n",
    "\n",
    "1. **Text → Lightweight Triples → KG Embeddings**  \n",
    "   *ECG* bypasses full KG construction by turning natural‑language (semi‑structured) mentions into triples. The resulting “graph” is then fed into standard embedding algorithms.\n",
    "\n",
    "2. **Text → Contextual Sub‑Graphs → Graph Matching**  \n",
    "   *Cross‑lingual alignment* builds a *topic entity graph* from text‑derived relations. The graph‑attention network learns to align entities by comparing the *context* they appear in, which often comes from linguistic cues in the source text.\n",
    "\n",
    "3. **Text → Type Information → Probabilistic Prediction**  \n",
    "   *TaRP* uses types (e.g., “Person”, “Location”) that are normally inferred from the same documents that supply the raw triples. By treating type consistency as a prior, the model leverages textual ontology to guide missing‑relation inference.\n",
    "\n",
    "---\n",
    "\n",
    "### Take‑away\n",
    "\n",
    "All three approaches demonstrate that **text can be directly leveraged to enrich, build, or align KG representations**—without the heavy engineering cost of traditional triple extraction or large‑scale graph construction. They also illustrate a spectrum of strategies:\n",
    "\n",
    "- **Direct embedding from text** (ECG)  \n",
    "- **Contextual graph construction for cross‑lingual tasks** (Cross‑lingual Graph Matching)  \n",
    "- **Ontological priors derived from text** (TaRP)\n",
    "\n",
    "These paradigms can be mixed or extended—e.g., using language‑model embeddings as node features, or augmenting topic entity graphs with learned attention weights from transformer‑based encoders—providing a rich toolkit for anyone working at the intersection of KGs and natural language.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7205838-6b0c-4f3e-817a-40b437d56e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = format_eval_prompt(query, context, answer)\n",
    "\n",
    "messages = [\n",
    "        {\n",
    "            'role': 'user',\n",
    "            'content': format_eval_prompt(query, context, answer),\n",
    "        },\n",
    "    ]\n",
    "\n",
    "raw =  client.chat(model, messages=messages, stream=False)\n",
    "print(raw.message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07afb345-3dd6-4a26-8f74-7b407b0d2cb3",
   "metadata": {},
   "source": [
    "## SciBERT embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6421bf0f-5571-4462-a159-170bc90bdd86",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Approaches combining knowledge graphs and text\"\n",
    "context = build_context_for_rag(chunks_sci)\n",
    "answer = \"\"\"**Approaches that fuse knowledge‑graph (KG) structure with textual information**\n",
    "\n",
    "| # | Approach / Model | Core idea | How KG and text are combined | Typical use‑case |\n",
    "|---|------------------|-----------|------------------------------|-----------------|\n",
    "| 1 | **Attribute‑driven semantic units** (Attributes as Semantic Units chapter) | Visual concepts (attributes) are mined from language resources (e.g., WordNet, caption corpora) and used as semantic pivots between image features and natural language. | Attributes form a lightweight KG (attribute ↔ concept graph). Textual features (e.g., word embeddings) are aligned to the same attributes, enabling cross‑modal retrieval and captioning. | Image‑to‑text generation, visual grounding, VQA. |\n",
    "| 2 | **Scene Description Graphs (SDGs)** | Each image is parsed into a graph where nodes are objects, attributes, and relations; edges encode spatial/semantic relations. | The SDG is enriched by two external knowledge sources:<br>• A *commonsense* KB derived from image captions (NLP‑extracted predicates).<br>• WordNet lexical ontology (synset relations). The graph thus merges visual detections, commonsense inference, and lexical semantics. | Automatic image captioning, image‑sentence alignment, visual storytelling. |\n",
    "| 3 | **Graph‑enhanced neural summarization** (Structured Neural Summarization) | A conventional sequence encoder (e.g., Transformer) is augmented with a graph encoder that operates on a *dependency / discourse graph* extracted from the input text. | The graph captures long‑range dependencies that are hard to learn from the sequence alone. Textual tokens are first embedded, then passed through the graph neural network (GNN), and finally merged back into the sequence decoder. | Summarizing long documents, abstractive summarization. |\n",
    "| 4 | **Retrieval‑based QA with triple‑convolutional networks** (TCNN & ATCNN) | The system retrieves a set of candidate knowledge entries from a QA KB, then reranks them by semantic matching. | Knowledge entries are first embedded as *triples* (subject–predicate–object). TCNN convolutions capture local patterns over these triples, while attention layers align the query text to the triple embeddings. | E‑commerce QA, customer support chatbots. |\n",
    "| 5 | **Graph‑aware language models (not in the given titles but widely studied)** | Pre‑train language models on KG triples (e.g., ERNIE, K-BERT) or use KG embeddings as auxiliary signals. | KG embeddings are injected into the transformer layers or used to bias attention. | Question answering, entity linking, relation extraction. |\n",
    "| 6 | **Joint KG–text representation learning** | Learn a shared vector space for KG entities and textual contexts (e.g., via co‑training). | Text passages containing entity mentions are aligned with KG nodes; a shared encoder (e.g., BERT) is fine‑tuned on both types of data. | Entity disambiguation, KG completion. |\n",
    "\n",
    "---\n",
    "\n",
    "### Common patterns in these methods\n",
    "\n",
    "1. **Graph construction**  \n",
    "   * From visual detections (SDG) → node = object/attribute, edge = spatial/semantic relation.  \n",
    "   * From language corpora → nodes = entities/words, edges = dependency or co‑occurrence.  \n",
    "   * From structured KBs (e.g., Freebase) → raw RDF triples.\n",
    "\n",
    "2. **Feature fusion**  \n",
    "   * **Early fusion** – concatenate raw text embeddings with KG embeddings before the encoder.  \n",
    "   * **Late fusion** – process text and KG separately and combine scores (e.g., reranking).  \n",
    "   * **Mid‑level fusion** – use GNNs to refine textual representations guided by graph structure.\n",
    "\n",
    "3. **Inference or reasoning**  \n",
    "   * Use graph propagation (GNN, message passing) to capture multi‑hop relationships.  \n",
    "   * Apply rule‑based or probabilistic inference on the KG to enrich textual outputs (e.g., commonsense reasoning in SDG).\n",
    "\n",
    "4. **Evaluation**  \n",
    "   * End‑to‑end tasks: image captioning, VQA, summarization, QA.  \n",
    "   * Alignment metrics: BLEU, METEOR for captions; ROUGE for summaries; precision/recall for retrieval.\n",
    "\n",
    "---\n",
    "\n",
    "### Take‑away\n",
    "\n",
    "Approaches that merge knowledge graphs and text typically build a graph that captures semantic or relational structure (from vision, language, or curated KBs) and then apply neural or graph‑based methods to fuse this structured knowledge with unstructured textual signals. The fusion can be performed at multiple stages of the pipeline, enabling richer representations that improve performance on downstream tasks such as image captioning, question answering, and summarization.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86cf52ae-ab46-4111-b859-1eb0605a3d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = format_eval_prompt(query, context, answer)\n",
    "\n",
    "messages = [\n",
    "        {\n",
    "            'role': 'user',\n",
    "            'content': format_eval_prompt(query, context, answer),\n",
    "        },\n",
    "    ]\n",
    "\n",
    "raw =  client.chat(model, messages=messages, stream=False)\n",
    "print(raw.message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96bc929-4bae-44e8-8125-f745ccb30a02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f6918a-c050-413f-80ff-ab8388f4ce88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb0b9a2-b815-42b5-9aeb-549c2c9e2e10",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Winter School - RAG",
   "language": "python",
   "name": "rag2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
